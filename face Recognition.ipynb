{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bdb45b0a8d15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#find the faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mfaceCascade\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'resources/haarcascade_frontalface_default.xml'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#haar cascade (trained for face detection) # i can create one for detecting whatever I want\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mfaces\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfaceCascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgGray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#(img, scale factor, min neighbour)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#face Recognition\n",
    "\n",
    "import cv2; import numpy as np\n",
    "\"\"\"\n",
    "this is the face recognition code\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "frameWidth= 640\n",
    "frameHeight= 480\n",
    "cap= cv2.VideoCapture(0)  #0 for the first (or only) camera     #1 for the second/rear camera when found\n",
    "cap.set(3,frameWidth)   #id 3 for the width --> width=640\n",
    "cap.set(4,frameHeight)  # id 4 for the height--> height=480\n",
    "cap.set(10,150) #id-10 for the brightness--> brightness increases \n",
    "\n",
    "while True:    \n",
    "    success, frame=cap.read()   #success is boolean variable (True or False)    \n",
    "    imgGray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#find the faces\n",
    "    faceCascade= cv2.CascadeClassifier('resources/haarcascade_frontalface_default.xml')  #haar cascade (trained for face detection) # i can create one for detecting whatever I want\n",
    "    faces= faceCascade.detectMultiScale(imgGray, 1.1, 4)   #(img, scale factor, min neighbour)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w,y+h), (255,0,0), 2)\n",
    "      \n",
    "    \n",
    "    \n",
    "    cv2.imshow('video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):   #it enables: press q button to close\n",
    "        break\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
